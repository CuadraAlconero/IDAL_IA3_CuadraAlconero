{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_Generators.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNU5A+/j5m1TnVcRYP4u2Go",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CuadraAlconero/IDAL_IA3_CuadraAlconero/blob/main/Keras_Generators.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meqs2hrSZc9b"
      },
      "source": [
        "# Generadores en Keras\n",
        "\n",
        "En este cuaderno vamos a estudiar como construir un generador personalizado con la api de Keras.\n",
        "\n",
        "Al igual que keras provee a sus usuarios con algunos generadores y capas diseñadas para el preprocesado de datos es posible construir un generador que realice operaciones definidas por los usuarios.\n",
        "\n",
        "Para esto necesitamos utilizar la clase de Keras Sequence.\n",
        "\n",
        "Sequence es una clase a partir de la cual se pueden diseñar otras con el objetivo de construir un generador personalizado, en este notebook vamos a construir un ejemplo de Sequence que cambia las resoluciones a la entrada antes de pasar la información a un modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjqeo_3ietPi"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /content/cats_and_dogs_filtered.zip\n",
        "!unzip cats_and_dogs_filtered.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3TA4GgNaRF5"
      },
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "from PIL import Image\n",
        "import os\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import shuffle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u6Z-7OzbHwb"
      },
      "source": [
        "Comenzamos definiendo el constructor de nuestra clase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJNQV7nyaW1x"
      },
      "source": [
        "class ImageResizer(Sequence):\n",
        "  def __init__(self, data_folder, img_shape, batch_size=32, to_fit=True):\n",
        "    self.data_folder = data_folder\n",
        "    self.files = [os.path.join(path, name) for path, subdirs, files in os.walk(data_folder) for name in files]\n",
        "    shuffle(self.files)\n",
        "    self.batch_size = batch_size\n",
        "    self.shape = img_shape\n",
        "    self.to_fit = True"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP-hjTcJbqZh"
      },
      "source": [
        "Tras definir el constructor necesitaremos definir los métodos \\_\\_getitem__ y \\_\\_len__.\n",
        "\n",
        "Estos métodos son los encargados de pasarle nuevas muestras al modelo durante el entrenamiento y su implementación es obligatoria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS9xcpm0bpnL"
      },
      "source": [
        "class ImageResizer(Sequence):\n",
        "  def __init__(self, data_folder, img_shape, batch_size=32, to_fit=True):\n",
        "    self.data_folder = data_folder\n",
        "    self.files = [os.path.join(path, name) for path, subdirs, files in os.walk(data_folder) for name in files]\n",
        "    shuffle(self.files)\n",
        "    self.batch_size = batch_size\n",
        "    self.shape = img_shape\n",
        "    self.to_fit = True\n",
        "\n",
        "  def __len__(self):\n",
        "    batches = int(np.floor(len(self.files) / self.batch_size))\n",
        "    return batches\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    batch_files = self.files[\n",
        "                             index * self.batch_size : (index + 1) * self.batch_size\n",
        "                            ]\n",
        "    if self.to_fit:\n",
        "      X = self._generate_X(batch_files)\n",
        "      y = self._generate_Y(batch_files)\n",
        "      return X, y\n",
        "    else:\n",
        "      X = self._generate_X(batch_files)\n",
        "      return X\n",
        "\n",
        "  def _generate_X(self, batch_files):\n",
        "    shape = [self.batch_size]\n",
        "    shape.extend(self.shape)\n",
        "    shape.extend([3])\n",
        "    X = np.zeros(shape=shape)\n",
        "    for i, file_ in enumerate(batch_files):\n",
        "      img = Image.open(file_)\n",
        "      resize_image = img.resize(self.shape)\n",
        "      array = np.array(resize_image)\n",
        "      X[i, :, :, :] = array\n",
        "    return X\n",
        "\n",
        "  def _generate_Y(self, batch_files):\n",
        "    y = list()\n",
        "    for file_ in batch_files:\n",
        "      label = file_.split(\"/\")\n",
        "      y.append(label[2])\n",
        "    df_labels = pd.DataFrame(y)\n",
        "    y_dummies = pd.get_dummies(df_labels).values\n",
        "    return y_dummies\n",
        "    "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqiA-kFeXKJR"
      },
      "source": [
        "generator = ImageResizer(\"cats_and_dogs_filtered/train\", (64,64), batch_size=128)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dTpN_ZkX7IZ"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(64,64,3))\n",
        "conv_layer = keras.layers.Conv2D(10, (3,3), activation=\"relu\",input_shape=(64,64,3))(input_layer)\n",
        "conv_layer2 = keras.layers.Conv2D(10, (3,3), activation=\"relu\")(conv_layer)\n",
        "pooling = keras.layers.MaxPool2D(pool_size=(2,2))(conv_layer2)\n",
        "flatten = keras.layers.Flatten(data_format=\"channels_last\")(pooling)\n",
        "dense = keras.layers.Dense(512, activation=\"tanh\")(flatten)\n",
        "classifier = keras.layers.Dense(2, activation=\"softmax\")(dense)\n",
        "model = keras.Model(inputs=input_layer, outputs=classifier)\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ-8uqA-Ypq-",
        "outputId": "f0d4475e-857d-4997-f1b1-460e76bf8ea1"
      },
      "source": [
        "model.fit(generator, epochs=5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "15/15 [==============================] - 15s 935ms/step - loss: 0.7393\n",
            "Epoch 2/5\n",
            "15/15 [==============================] - 15s 946ms/step - loss: 0.6991\n",
            "Epoch 3/5\n",
            "15/15 [==============================] - 14s 940ms/step - loss: 0.7005\n",
            "Epoch 4/5\n",
            "15/15 [==============================] - 14s 925ms/step - loss: 0.6994\n",
            "Epoch 5/5\n",
            "15/15 [==============================] - 14s 941ms/step - loss: 0.6963\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2b99004dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD25BHL-GqIh"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81XrTDU2euZc"
      },
      "source": [
        "# Ejercicio\n",
        "\n",
        "Construíd un generador de keras e incluíd la lógica de padding descrita en el cuaderno anterior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1JhFum5KCVw"
      },
      "source": [
        "class ImageResizer(Sequence):\n",
        "  def __init__(self, data_folder, img_shape, batch_size=32, to_fit=True):\n",
        "    self.data_folder = data_folder\n",
        "    self.files = [os.path.join(path, name) for path, subdirs, files in os.walk(data_folder) for name in files]\n",
        "    shuffle(self.files)\n",
        "    self.batch_size = batch_size\n",
        "    self.shape = img_shape\n",
        "    self.to_fit = True\n",
        "\n",
        "  def __len__(self):\n",
        "    batches = int(np.floor(len(self.files) / self.batch_size))\n",
        "    return batches\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    batch_files = self.files[\n",
        "                             index * self.batch_size : (index + 1) * self.batch_size\n",
        "                            ]\n",
        "    if self.to_fit:\n",
        "      X = self._generate_X(batch_files)\n",
        "      y = self._generate_Y(batch_files)\n",
        "      return X, y\n",
        "    else:\n",
        "      X = self._generate_X(batch_files)\n",
        "      return X\n",
        "\n",
        "  def _generate_X(self, batch_files):\n",
        "    shape = [self.batch_size]\n",
        "    shape.extend(self.shape)\n",
        "    shape.extend([3])\n",
        "    X = np.zeros(shape=shape)\n",
        "    for i, file_ in enumerate(batch_files):\n",
        "      img = Image.open(file_)\n",
        "      resize_image = self._change_resolution(img)\n",
        "      padding_image = self._pad_img(resize_image)\n",
        "      X[i, :, :, :] = padding_image\n",
        "    return X\n",
        "\n",
        "  def _pad_img(self, img):\n",
        "    width, height = img.size\n",
        "    desired_resolution = self.shape[0]\n",
        "    array = np.array(img)\n",
        "    if width > height:\n",
        "      total_pad = desired_resolution - height\n",
        "      pad = total_pad/2\n",
        "      if isinstance(pad, float):\n",
        "        pad_0 = int(np.ceil(pad))\n",
        "        pad_1 = int(np.floor(pad))\n",
        "        padded_image = np.pad(array, ((pad_0, pad_1),(0,0),(0,0)))\n",
        "      else:\n",
        "        padded_image = np.pad(array, ((pad, pad),(0,0),(0,0)))\n",
        "    else:\n",
        "      total_pad = desired_resolution - width\n",
        "      pad = total_pad/2\n",
        "      if isinstance(pad, float):\n",
        "        pad_0 = int(np.ceil(pad))\n",
        "        pad_1 = int(np.floor(pad))\n",
        "        padded_image = np.pad(array, ((0,0),(pad_0, pad_1),(0,0)))\n",
        "      else:\n",
        "        padded_image = np.pad(array, ((0,0),(pad, pad),(0,0)))\n",
        "    return padded_image\n",
        "\n",
        "  def _change_resolution(self, img):\n",
        "    desired_resolution = self.shape[0]\n",
        "    width, height = img.size\n",
        "    if width > height:\n",
        "      aspect_relatio = width/height\n",
        "      new_width = desired_resolution\n",
        "      new_height = round(desired_resolution/aspect_relatio)\n",
        "      resized_img = img.resize((new_width,new_height))\n",
        "    else:\n",
        "      aspect_relatio = height/width\n",
        "      new_height = desired_resolution\n",
        "      new_width = round(desired_resolution/aspect_relatio)\n",
        "      resized_img = img.resize((new_width,new_height))\n",
        "    return resized_img\n",
        "\n",
        "  def _generate_Y(self, batch_files):\n",
        "    y = list()\n",
        "    for file_ in batch_files:\n",
        "      label = file_.split(\"/\")\n",
        "      y.append(label[2])\n",
        "    df_labels = pd.DataFrame(y)\n",
        "    y_dummies = pd.get_dummies(df_labels).values\n",
        "    return y_dummies"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqtaQmclN9Gl"
      },
      "source": [
        "generator = ImageResizer(\"cats_and_dogs_filtered/train\", (64,64), batch_size=128)\n",
        "input_layer = keras.layers.Input(shape=(64,64,3))\n",
        "conv_layer = keras.layers.Conv2D(10, (3,3), activation=\"relu\",input_shape=(64,64,3))(input_layer)\n",
        "conv_layer2 = keras.layers.Conv2D(10, (3,3), activation=\"relu\")(conv_layer)\n",
        "pooling = keras.layers.MaxPool2D(pool_size=(2,2))(conv_layer2)\n",
        "flatten = keras.layers.Flatten(data_format=\"channels_last\")(pooling)\n",
        "dense = keras.layers.Dense(512, activation=\"tanh\")(flatten)\n",
        "classifier = keras.layers.Dense(2, activation=\"softmax\")(dense)\n",
        "model = keras.Model(inputs=input_layer, outputs=classifier)\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wuu3ejqOD14",
        "outputId": "0b2f3282-dafc-4571-dbb2-21d8f1e6782e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(generator, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "15/15 [==============================] - 15s 964ms/step - loss: 0.8306\n",
            "Epoch 2/5\n",
            " 6/15 [===========>..................] - ETA: 8s - loss: 0.6980"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_m00pi_wlWx"
      },
      "source": [
        "\n"
      ]
    }
  ]
}